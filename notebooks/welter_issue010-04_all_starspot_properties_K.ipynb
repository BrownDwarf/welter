{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "How's it look?\n",
    "\n",
    "Now with **Mixture model**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have orders m111, m113, m114, m115 complete.  Let's plot all of the results on the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_o = 23\n",
    "go = np.arange(72, 94+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_s = 200\n",
    "n_ws = 40\n",
    "n_par = 14+1\n",
    "wss = np.zeros((n_s*n_ws, n_par, n_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in go:\n",
    "    ws = np.load(\"../sf/m{:03d}/output/mix_emcee/run01/emcee_chain.npy\".format(m))\n",
    "    burned = ws[:, -1.0*n_s:,:]\n",
    "    xs, ys, zs = burned.shape\n",
    "    fc = burned.reshape(xs*ys, zs)\n",
    "    wss[:, :-1, m-72] = fc\n",
    "    wss[:, -1, m-72] = 10**fc[:,7] / ( 10**fc[:,5] + 10**fc[:,7] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm pretty sure that what I'm about to do is *not allowed* by probability theory.  \n",
    "Specifically, I'm \"adding probabilities\" an operation that is not principled... I think.  \n",
    "It would be great to ask a statistician about this!\n",
    "In any case, the result can be considered a consistency check, or an order-weighted average joint probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb = np.array([])\n",
    "tt = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in np.arange(n_o):\n",
    "    bb = np.append(bb, wss[:,-1, m], axis=0)\n",
    "    tt = np.append(tt, wss[:,6, m], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.jointplot(bb, tt, kind='scatter', alpha=0.005)\n",
    "ax.ax_joint.set_ylabel('Star spot $T_{\\mathrm{eff}}$')\n",
    "ax.ax_joint.set_xlabel('Coverage fraction $f$')\n",
    "#plt.savefig('Star_spot_measurement.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a while:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.jointplot(bb, tt, kind='kde')\n",
    "ax.ax_joint.set_ylabel('Star spot $T_{\\mathrm{eff}}$')\n",
    "ax.ax_joint.set_xlabel('Coverage fraction $f$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a pandas dataframe of the average values from the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('../data/analysis/IGRINS_mix_emcee_last200.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the metadata columns from the old dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What columns do we want?\n",
    "\n",
    "- All the same as the last array: median and 2 sigma ranges. (6+6)*3 = 36 \n",
    "- Teff2 and Omega2 and 2 sigma ranges. (1+1)*3 = 6\n",
    "- Conversion of Omega2 and Omega1 into fill factor and 2 sigma ranges. (1)*3 = 3\n",
    "- Metadata about the number of samples and the burn-in assumed to compute the above values.\n",
    "    - We can get more metadata from the `sacct` log from slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in new_df.m_val:\n",
    "    ind = new_df.index[new_df.m_val == m]\n",
    "    try:\n",
    "        ws = np.load(\"../sf/m{:03d}/output/mix_emcee/run01/emcee_chain.npy\".format(m))\n",
    "        new_df.set_value(ind, 'inference', True)\n",
    "    except:\n",
    "        new_df.set_value(ind, 'inference', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs = new_df.columns[7:-5:3]\n",
    "bases = cs.str[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_inds = np.hstack([np.arange(6), np.arange(8, 14), [6, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffixes = ['_05p', '_50p','_95p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_dict = {key:val for key, val in zip(bases, base_inds)}\n",
    "suffix_dict = {key:val for key, val in zip(suffixes, [5, 50, 95])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in new_df.m_val[new_df.inference]:\n",
    "    ind = new_df.index[new_df.m_val == m]\n",
    "    ws = np.load(\"../sf/m{:03d}/output/mix_emcee/run01/emcee_chain.npy\".format(m))\n",
    "    burned = ws[:, -1*n_s:,:]\n",
    "    xs, ys, zs = burned.shape\n",
    "    fc = burned.reshape(xs*ys, zs)\n",
    "    bb = 10**fc[:,7] / ( 10**fc[:,5] + 10**fc[:,7] )\n",
    "    for suffix in suffixes:\n",
    "        new_df.set_value(ind, 'ff'+suffix, np.percentile(bb, suffix_dict[suffix]))\n",
    "        for base in bases[:-1]:\n",
    "            new_df.set_value(ind, base+suffix, np.percentile(fc[:, base_dict[base]], suffix_dict[suffix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv('../data/analysis/IGRINS_mix_emcee_last200.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
